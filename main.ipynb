{"cells":[{"cell_type":"markdown","id":"rikW3d2E38Gj","metadata":{"id":"rikW3d2E38Gj"},"source":["# **SemEval 2024 Task 2: Safe Biomedical Natural Language Inference**\n","### Topic:  Fine-Tuning Pre-trained Transformer Models for Detecting Annotation Artifacts for Natural Language Inference Tasks\n","\\\n","Model_1: `BERT-base-cased` \\\n","Model_2: `medicalai/ClinicalBERT` \\\n","Model_3: `pritamdeka/BioBert-PubMed200kRCT` \\\n","Model_4: `allenai/biomed_roberta_base` \\\n","(Model_5: `yikuan8/Clinical-Longformer`)"]},{"cell_type":"markdown","id":"I57Vqw0c5WGy","metadata":{"id":"I57Vqw0c5WGy"},"source":["# **Prerequisites**"]},{"cell_type":"markdown","id":"4uVhDAcIfN1q","metadata":{"id":"4uVhDAcIfN1q"},"source":["## **Installing the required packages**\n","This is especially important when:\n","- the required packages/libraries are not previously installed on a local system or\n","- Google Colab is used"]},{"cell_type":"code","execution_count":null,"id":"a02798fd-442d-4f09-871f-d9738d25e5b4","metadata":{"collapsed":true,"id":"a02798fd-442d-4f09-871f-d9738d25e5b4"},"outputs":[],"source":["!pip install transformers\n","!pip install datasets\n","!pip install accelerate -U\n","!pip install pyarrow\n","!pip install -q wandb\n","!pip install -U ray\n","!pip install optuna"]},{"cell_type":"markdown","id":"Pt2AdyAWhbXj","metadata":{"id":"Pt2AdyAWhbXj"},"source":["## **Import libraries**\n","Import required libraries and check if GPU is available for training.\n"]},{"cell_type":"code","execution_count":null,"id":"gRzOXqxsUjib","metadata":{"id":"gRzOXqxsUjib"},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n","import datasets\n","import json\n","\n","import transformers\n","from transformers import BertForSequenceClassification, AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, RobertaForSequenceClassification, AutoConfig\n","import torch\n","import pyarrow as pa\n","\n","import wandb\n","import optuna\n","\n","# test if GPU is available\n","if torch.cuda.is_available():\n","    print(\"GPU available. Training on GPU.\")\n","else:\n","    print(\"No GPU available. Training on CPU.\")"]},{"cell_type":"markdown","id":"XEf5H9g_5upn","metadata":{"id":"XEf5H9g_5upn"},"source":["# **1. Preprocessing**"]},{"cell_type":"markdown","id":"YagCvPlEjf0O","metadata":{"id":"YagCvPlEjf0O"},"source":["## **1.1 Mapping Trial IDs to CTR instances**\n"]},{"cell_type":"code","execution_count":null,"id":"yDOG9E54EK0w","metadata":{"id":"yDOG9E54EK0w"},"outputs":[],"source":["# mapping class labels to IDs & vice versa\n","label2id = {\"Contradiction\": 0, \"Entailment\": 1}\n","id2label= {0: \"Contradiction\", 1: \"Entailment\"}\n","\n","# Mapping Trial IDs to CTR instances\n","def id_to_CTR(raw_texts):\n","  # dictionary to access study information (CTRs) via trial-ids\n","  id_to_clinical_trial_record = {}\n","\n","  for instance in raw_texts:\n","    id = instance['clinical_trial_id'] # load ID of instance -> key: 'clinical_trial_id'\n","    id_to_clinical_trial_record[id] = instance\n","\n","  return id_to_clinical_trial_record"]},{"cell_type":"markdown","id":"A_laD8LCkQcQ","metadata":{"id":"A_laD8LCkQcQ"},"source":["**1.2 Load NLI4CT dataset from Huggingface**\n","see https://huggingface.co/datasets/bigbio/sem_eval_2024_task_2 for dataset card"]},{"cell_type":"code","execution_count":null,"id":"yguq--0B1aIT","metadata":{"id":"yguq--0B1aIT"},"outputs":[],"source":["# import dataset from Huggingface\n","annotations = datasets.load_dataset(\"bigbio/sem_eval_2024_task_2\", name=\"sem_eval_2024_task_2_source\") # hypothesis (statements)\n","raw_texts = datasets.load_dataset(\"bigbio/sem_eval_2024_task_2\", name=\"sem_eval_2024_task_2_ct\")['train'] # CTR instances (premises)"]},{"cell_type":"markdown","id":"J_ljW_xGk9OV","metadata":{"id":"J_ljW_xGk9OV"},"source":["## **1.3 Data Transformation**\n","Transform the loaded dataset into a Huggingface `Dataset` that can be processed by an object of the `Tokenizer` class."]},{"cell_type":"code","execution_count":null,"id":"wXBgTrCNCVX4","metadata":{"id":"wXBgTrCNCVX4"},"outputs":[],"source":["# transform data to required format to be processed from Tokenizer\n","\n","def transform_data(annotations, id_to_clinical_trial_record, label2ids, setting):\n","\n","  data_raw = {\"train\": [], \"validation\": [], \"practice_test\": [], \"test\": []}\n","\n","  if setting==\"statement_only\":  # annotation artifacts\n","    for data_type in annotations.keys():\n","      for instance in annotations[data_type]:\n","          # get the label of the training instance -> e.g. 0 for \"contradiction\"\n","          if data_type in ('practice_test', 'test'):\n","            label = 0  # int label is needed for making predictions but does not influence these\n","          else:\n","            label = label2ids[instance['label']]\n","\n","          statement = instance['statement'] # statement from training data\n","          text = statement\n","          relevant_info = {\"label\": label, \"text\": text}\n","\n","          data_raw[data_type].append(relevant_info)\n","\n","# -----------------------------------------------------depreciated-----------------------------------------------------\n","\n","  elif setting==\"primary_sec_statement\":\n","    for data_type in annotations.keys():\n","      for instance in annotations[data_type]:\n","          # get the label of the training instance -> e.g. 0 for \"contradiction\"\n","          if data_type in ('practice_test', 'test'):\n","            label = 0  # int label is needed for making predictions but does not influence these\n","          else:\n","            label = label2ids[instance['label']]\n","\n","          primary_id = instance['primary_id'] # ID of the primary section that supports (or not supports) the statement -> e.g. '00466f98-52b8-41f3-9bf1-2edaad950be9'\n","          primary_CTR = id_to_clinical_trial_record[primary_id] # get the CTR for the given primary ID -> e.g. 'NCT02504424'\n","          primary_section = primary_CTR[instance['section_id'].lower().replace(\" \", \"_\")] # content of primary section of CTR\n","\n","          statement = instance['statement'] # statement from training data\n","\n","          text = (\".\".join(primary_section), statement)\n","          relevant_info = {\"label\": label, \"text\": text}\n","\n","          data_raw[data_type].append(relevant_info)\n","\n","  elif setting==\"secondary_sec_statement\":\n","    for data_type in annotations.keys():\n","      for instance in annotations[data_type]:\n","          # get the label of the training instance -> e.g. 0 for \"contradiction\"\n","          if data_type in ('practice_test', 'test'):\n","            label = 0  # int label is needed for making predictions but does not influence these\n","          else:\n","            label = label2ids[instance['label']]\n","\n","          secondary_id = instance['secondary_id'] # ID of the secondary section that supports (or not supports) the statement -> e.g. '00466f98-52b8-41f3-9bf1-2edaad950be9'\n","\n","          if secondary_id:\n","            secondary_CTR = id_to_clinical_trial_record[secondary_id] # get the CTR for the given secondary ID -> e.g. 'NCT02504424'\n","            secondary_section = secondary_CTR[instance['section_id'].lower().replace(\" \", \"_\")] # content of secondary section of CTR\n","\n","            statement = instance['statement'] # statement from training data\n","\n","            text = (\".\".join(secondary_section), statement)\n","            relevant_info = {\"label\": label, \"text\": text}\n","\n","            data_raw[data_type].append(relevant_info)\n","\n","  elif setting==\"primary_secondary_sec_statement\":\n","    for data_type in annotations.keys():\n","        for instance in annotations[data_type]:\n","            # get the label of the training instance -> e.g. 0 for \"contradiction\"\n","            if data_type in ('practice_test', 'test'):\n","              label = 0  # int label is needed for making predictions but does not influence these\n","            else:\n","              label = label2ids[instance['label']]\n","\n","            primary_id = instance['primary_id'] # ID of the primary section that supports (or not supports) the statement -> e.g. '00466f98-52b8-41f3-9bf1-2edaad950be9'\n","            primary_CTR = id_to_clinical_trial_record[primary_id] # get the CTR for the given primary ID -> e.g. 'NCT02504424'\n","            primary_section = primary_CTR[instance['section_id'].lower().replace(\" \", \"_\")] # content of primary section of CTR\n","\n","            secondary_id = instance['secondary_id'] # ID of the secondary section that supports (or not supports) the statement\n","\n","            if secondary_id:\n","              secondary_CTR = id_to_clinical_trial_record[secondary_id] # get the CTR for the given secondary ID\n","              secondary_section = secondary_CTR[instance['section_id'].lower().replace(\" \", \"_\")] # content of secondary section of CTR\n","\n","              statement = instance['statement'] # statement from training data\n","\n","              text = (\".\".join(primary_section), \".\".join(secondary_section), statement)\n","              relevant_info = {\"label\": label, \"text\": text}\n","\n","              data_raw[data_type].append(relevant_info)\n","\n","\n","  for data_type, data in data_raw.items():\n","    table = pa.Table.from_pydict({key: [item[key] for item in data] for key in data[0]})\n","    data_raw[data_type] = datasets.arrow_dataset.Dataset(table)\n","\n","  return datasets.dataset_dict.DatasetDict(data_raw)"]},{"cell_type":"markdown","id":"7WrKKTV2qOj3","metadata":{"id":"7WrKKTV2qOj3"},"source":["# **2. Training**"]},{"cell_type":"markdown","id":"xWP39nMef4vO","metadata":{"id":"xWP39nMef4vO"},"source":["## **2.1 Setting *path*-variable to store results**\n","- If run locally, enter local path\n","- If Google Colab is used, please mount your Google Drive and enter the required path."]},{"cell_type":"code","execution_count":null,"id":"P4UAiHZI2Xob","metadata":{"id":"P4UAiHZI2Xob"},"outputs":[],"source":["from google.colab import drive\n","import google.colab\n","\n","path = \"./\"\n","\n","if 'google.colab' in str(get_ipython()):\n","  drive.mount('/content/drive')\n","\n","  user_input = str(input(\"Enter path: \"))# set path to directory for saving models\n","  path = user_input if user_input else path\n","  print(f\"Path: {path}\")\n","else:\n","  user_input = str(input(\"Enter path: \")) # set path to directory for saving models\n","  path = user_input if user_input else path\n","  print(f\"Path: {path}\")"]},{"cell_type":"markdown","id":"tXt656a-htZb","metadata":{"id":"tXt656a-htZb"},"source":["## **2.2 Weights & Biases**\n","Provide login credentials to track experimental results during training. Please enter key after running this cell."]},{"cell_type":"code","execution_count":null,"id":"HIuhFjhz4Kmt","metadata":{"id":"HIuhFjhz4Kmt"},"outputs":[],"source":["# Login into wandb: copy key from account\n","wandb.login()"]},{"cell_type":"markdown","id":"9no56GK_iBr3","metadata":{"id":"9no56GK_iBr3"},"source":["## **2.3 Implementation of Evaluation Metrics**\n","We report\n","- Accuracy\n","- Precision\n","- Recall\n","- Macro F1-Score\n","\n","for the **entailment-class** on the development set using the `sklearn.metric`-library."]},{"cell_type":"code","execution_count":null,"id":"PjCoXjDnEK0z","metadata":{"id":"PjCoXjDnEK0z"},"outputs":[],"source":["# compute metrics for class 1 (entailment)\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred.predictions.argmax(-1), eval_pred.label_ids\n","\n","    accuracy = accuracy_score(labels, predictions)\n","    precision = precision_score(labels, predictions, average=\"macro\")\n","    recall = recall_score(labels, predictions, average=\"macro\")\n","    f1 = f1_score(labels, predictions, average=\"macro\")\n","\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"]},{"cell_type":"markdown","id":"tBn86RfRlm5B","metadata":{"id":"tBn86RfRlm5B"},"source":["## **2.4 Input Parameters**\n","Setting the model input configurations:\n","- For NLI task: combinations of hypothesis (*statement*) and premise(s) (*section(s)*)\n","- For detecting Annotation Artifacts: hypothesis (*statement only*)\n","\n","Please enter the desired digit."]},{"cell_type":"code","execution_count":null,"id":"zxmWoqY83uUD","metadata":{"id":"zxmWoqY83uUD"},"outputs":[],"source":["# set setting\n","# possible settings\n","settings = {\n","    1: \"statement_only\",\n","    2: \"primary_sec_statement\",\n","    3: \"secondary_sec_statement\",\n","    4: \"primary_secondary_sec_statement\",\n","}\n","\n","input_setting = int(input(\"Choose a setting: \\n\" +\n","    f\"[1] {settings[1]} \\n\" +\n","    f\"[2] {settings[2]} \\n\" +\n","    f\"[3] {settings[3]} \\n\" +\n","    f\"[4] {settings[4]} \\n\"))\n","\n","setting = settings[input_setting] # <- choose your desired setting\n","print(f\"Selected setting: {setting}\")"]},{"cell_type":"markdown","id":"h2gbbcCrpAns","metadata":{"id":"h2gbbcCrpAns"},"source":["## **2.5 Model Selection**\n","Setting the model for the task:\n","\n","- `pritamdeka/BioBert-PubMed200kRCT`\n","- `medicalai/ClinicalBERT`\n","- `BERT-base-cased`\n","- `allenai/biomed_roberta_base`\n","\n","**Future Work:**\n","- (`yikuan8/Clinical-Longformer`)\n","\n","Please enter the desired digit."]},{"cell_type":"code","execution_count":null,"id":"S4Hd6UZG4p7J","metadata":{"id":"S4Hd6UZG4p7J"},"outputs":[],"source":["# set model\n","# possible models\n","models = {\n","    1: \"bert-base-cased\", # BERT-base-cased\n","    2: \"medicalai/ClinicalBERT\", # medicalai/ClinicalBERT\n","    3: \"pritamdeka/BioBert-PubMed200kRCT\", # pritamdeka/BioBert-PubMed200kRCT\n","    4: \"allenai/biomed_roberta_base\", # allenai/biomed_roberta_base\n","    5: \"yikuan8/Clinical-Longformer\", # yikuan8/Clinical-Longformer\n","}\n","\n","input_model = int(input(\"Choose a model: \\n\" +\n","    f\"[1] {models[1]} \\n\" +\n","    f\"[2] {models[2]} \\n\" +\n","    f\"[3] {models[3]} \\n\" +\n","    f\"[4] {models[4]} \\n\" +\n","    f\"[5] {models[5]} \\n\"))\n","\n","model_name = models[input_model] # <- choose your desired model\n","print(f\"Selected model: {model_name}\")"]},{"cell_type":"markdown","id":"c-LPtewhq1Kz","metadata":{"id":"c-LPtewhq1Kz"},"source":["## **2.6 Fine-Tuned Hyperparameters**\n","Stored fine-tuned hyperparameters for each model\n","\n","- `pritamdeka/BioBert-PubMed200kRCT`\n","- `medicalai/ClinicalBERT`\n","- `BERT-base-cased`\n","- `allenai/biomed_roberta_base`\n","\n","**Future Work:**\n","- (`yikuan8/Clinical-Longformer`)\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"id":"Cqdu9HEI3x_M","metadata":{"id":"Cqdu9HEI3x_M"},"outputs":[],"source":["# # set hyperparameters\n","# # TODO: new added parameters also need to be added in training_arguments below\n","train_args = {\n","   models[1]: { # BERT-base-cased\n","       settings[1]: { # statement_only\n","           \"epochs\": 5, # epochs to train\n","           \"batch_size\": 25, # batch size\n","           \"lr\": 7.908000560027878e-05, # learning rate\n","           \"padd\": \"longest\", # padding\n","           \"trunc\": \"only_first\", # truncation\n","           \"max_len\": 512, # max input length\n","           \"warmup\": 0, # warm up steps\n","           \"chosen_seed\": 49, # random seed\n","           \"weight_dec\": 0.37535936878564713, # weight decay\n","       },\n","       settings[2]: { # primary_sec_statement\n","           \"epochs\": 3, # epochs to train\n","           \"batch_size\": 4, # batch size\n","           \"lr\": 0.00000917445256433797, # learning rate\n","           \"padd\": \"longest\", # padding\n","           \"trunc\": \"only_first\", # truncation\n","           \"max_len\": 512, # max input length\n","           \"warmup\": 0, # warm up steps\n","           \"chosen_seed\": 40, # random seed\n","           \"weight_dec\": 0.01, # weight decay\n","       },\n","   },\n","   models[2]: { # medicalai/ClinicalBERT\n","       settings[1]: { # statement_only\n","           \"epochs\": 3, # epochs to train\n","           \"batch_size\": 16, # batch size\n","           \"lr\": 0.00000334675755041166, # learning rate\n","           \"padd\": \"longest\", # padding\n","           \"trunc\": \"only_first\", # truncation\n","           \"max_len\": 512, # max input length\n","           \"warmup\": 50, # warm up steps\n","           \"chosen_seed\": 22, # random seed\n","           \"weight_dec\": 0.01, # weight decay\n","       },\n","   },\n","   models[3]: { # pritamdeka/BioBert-PubMed200kRCT\n","       settings[1]: { # statement_only\n","           \"epochs\": 4, # epochs to train\n","           \"batch_size\": 20, # batch size\n","           \"lr\": 0.00010274905958215669, # learning rate\n","           \"padd\": \"longest\", # padding\n","           \"trunc\": \"only_first\", # truncation\n","           \"max_len\": 512, # max input length\n","           \"warmup\": 204, # warm up steps\n","           \"chosen_seed\": 1, # random seed\n","           \"weight_dec\": 0.29127004443098675, # weight decay\n","       },\n","   },\n","   models[4]: { # allenai/biomed_roberta_base\n","       settings[1]: { # statement_only\n","           \"epochs\": 4, # epochs to train\n","           \"batch_size\": 20, # batch size\n","           \"lr\": 0.0001006811343796169, # learning rate\n","           \"padd\": \"longest\", # padding\n","           \"trunc\": \"only_first\", # truncation\n","           \"max_len\": 512, # max input length\n","           \"warmup\": 124, # warm up steps\n","           \"chosen_seed\": 6, # random seed\n","           \"weight_dec\": 0.24031521060055702, # weight decay\n","       },\n","   },\n","   models[5]: { # yikuan8/Clinical-Longformer\n","       settings[1]: { # statement_only\n","           \"epochs\": 5, # epochs to train\n","           \"batch_size\": 32, # batch size\n","           \"lr\": 2e-5, # learning rate\n","           \"padd\": \"longest\", # padding\n","           \"trunc\": \"only_first\", # truncation\n","           \"max_len\": 512, # max input length\n","           \"warmup\": 0, # warm up steps\n","           \"chosen_seed\": 22, # random seed\n","           \"weight_dec\": 0.01, # weight decay\n","       },\n","   },\n"," }"]},{"cell_type":"markdown","id":"aGvE2WdUUbvy","metadata":{"id":"aGvE2WdUUbvy"},"source":["## **2.7 Loading selected Model and Tokenizer**\n","- selected model is loaded via `AutoModelForSequenceClassification`\n","- as tokenizer we use `AutoTokenizer` for the selected model\n","- `tokenize_function` is defined for mapping\n"]},{"cell_type":"code","execution_count":null,"id":"KhpekRGWEK0y","metadata":{"collapsed":true,"id":"KhpekRGWEK0y"},"outputs":[],"source":["# build ID to CTR mapping and transform data in data structure used by Tokenizer and Model\n","id_to_clinical_trial_record = id_to_CTR(raw_texts)\n","data = transform_data(annotations, id_to_clinical_trial_record, label2id, setting)\n","\n","# model und tokenizer initialisation\n","def model_init():\n","    return AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, label2id=label2id, id2label=id2label, ignore_mismatched_sizes=True, return_dict=True)\n","\n","model = model_init()\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","def tokenize_function(examples):\n","    return tokenizer(\n","        examples[\"text\"],\n","        padding=train_args[model_name][setting][\"padd\"],\n","        truncation=train_args[model_name][setting][\"trunc\"],\n","        max_length=train_args[model_name][setting][\"max_len\"])\n","\n","tokenized_datasets = data.map(tokenize_function, batched=True)"]},{"cell_type":"markdown","id":"wCUatzUlWTW2","metadata":{"id":"wCUatzUlWTW2"},"source":["## **2.8 Setting Training Arguments**\n","`TrainingArguments` takes parameters from the `train_args` defined in 2.6\n"]},{"cell_type":"code","execution_count":null,"id":"_XjtGD82EK0z","metadata":{"id":"_XjtGD82EK0z"},"outputs":[],"source":["training_args = TrainingArguments(\n","  output_dir=f\"{path}/{model_name}_{setting}\",  # output directory for results\n","  num_train_epochs=train_args[model_name][setting][\"epochs\"],  # number of training epochs\n","  per_device_train_batch_size=train_args[model_name][setting][\"batch_size\"],  # batch size per device during training\n","  evaluation_strategy=\"epoch\",  # evaluate in the end of each epoch\n","  use_cpu=False,\n","  learning_rate=train_args[model_name][setting][\"lr\"],\n","  logging_steps=10, # default 500\n","  weight_decay=train_args[model_name][setting][\"weight_dec\"],\n","  gradient_accumulation_steps=4, # same for all models & settings\n","  warmup_steps=train_args[model_name][setting][\"warmup\"],\n","  load_best_model_at_end=True,\n","  metric_for_best_model=\"f1\",\n","  save_strategy=\"epoch\",\n","  seed=train_args[model_name][setting][\"chosen_seed\"],\n",")"]},{"cell_type":"markdown","id":"m0OwZfqvXNdE","metadata":{"id":"m0OwZfqvXNdE"},"source":["## **2.9 Experiment Tracking with Weights and Biases**\n","Initialize `wandb` with the parameters from the `train_args` defined in 2.6\n"]},{"cell_type":"code","execution_count":null,"id":"tchNwnkZJ99l","metadata":{"id":"tchNwnkZJ99l"},"outputs":[],"source":["# start a new wandb run to track this script\n","wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=model_name.replace(\"/\", \"_\"), # problems with / in project name\n","    # track hyperparameters and run metadata\n","    config={\n","        \"model\": model_name,\n","        \"learning_rate\": train_args[model_name][setting][\"lr\"],\n","        \"logging_steps\": 10,\n","        \"num_epochs\": train_args[model_name][setting][\"epochs\"],\n","        \"train_samples\": setting,\n","        \"architecture\": \"Pre-Trained-Transfomer\",\n","        \"dataset\": \"bigbio/sem_eval_2024_task_2\",\n","        \"batch_size\": train_args[model_name][setting][\"batch_size\"],\n","        \"padding\": train_args[model_name][setting][\"padd\"],\n","        'truncation': train_args[model_name][setting][\"trunc\"],\n","        'max_length': train_args[model_name][setting][\"max_len\"],\n","        'warmup_steps': train_args[model_name][setting][\"warmup\"],\n","        'seed': train_args[model_name][setting][\"chosen_seed\"],\n","        'weight_decay': train_args[model_name][setting][\"weight_dec\"],\n","    }\n",")\n","wandb.run.name = model_name + \"_\" + setting # wandb run name"]},{"cell_type":"markdown","id":"PBsS91xiawtj","metadata":{"id":"PBsS91xiawtj"},"source":["## **2.10 Initialize Trainer**\n","for evaluation we use `compute_metrics` defined in 2.3\n"]},{"cell_type":"code","execution_count":null,"id":"tYdctW1aVn3a","metadata":{"id":"tYdctW1aVn3a"},"outputs":[],"source":["trainer = Trainer(\n","    args=training_args,  # settings for training (TrainingArguments)\n","    train_dataset=tokenized_datasets[\"train\"],  # train set\n","    eval_dataset=tokenized_datasets[\"validation\"], # dev set\n","    tokenizer=tokenizer,  # Tokenizer\n","    compute_metrics=compute_metrics, # evaluation metrics\n","    model_init=model_init,\n","  )"]},{"cell_type":"markdown","id":"5FQYH_Ppc1Wq","metadata":{"id":"5FQYH_Ppc1Wq"},"source":["## **2.11 Hyperparameter Tuning with `optuna`**\n","- creating `optuna` study for 10 trials\n","- `objective` is set to minimize loss and maximize F1\n"]},{"cell_type":"code","execution_count":null,"id":"ud6b0BpfJ6Ce","metadata":{"id":"ud6b0BpfJ6Ce"},"outputs":[],"source":["def objective(trial):\n","  \t# defining ranges for hyperparameter search\n","    learning_rate = trial.suggest_float('learning_rate', 5e-5, 1e-2, log=True)\n","    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 6) # <- change max for larger models\n","    per_device_train_batch_size = trial.suggest_int('per_device_train_batch_size', 2, 20)\n","    wd = trial.suggest_float('weight_decay', 0.1, 0.4)\n","    wus = trial.suggest_int('warm_up_steps', 5, 400)\n","    random_seed = trial.suggest_int('seed', 0, 40)\n","\n","    # use these parameters for training\n","    training_args = TrainingArguments(\n","        output_dir='./results',\n","        learning_rate=learning_rate,\n","        num_train_epochs=num_train_epochs,\n","        per_device_train_batch_size=per_device_train_batch_size,\n","        evaluation_strategy=\"epoch\",\n","        use_cpu=False,\n","        logging_steps=10,\n","        weight_decay=wd,\n","        gradient_accumulation_steps=4,\n","        warmup_steps=wus,\n","        seed=random_seed,\n","    )\n","\n","    trainer = Trainer(\n","        model_init=model_init,\n","        args=training_args,\n","        train_dataset=tokenized_datasets[\"train\"],\n","        eval_dataset=tokenized_datasets[\"validation\"], # dev set\n","        tokenizer=tokenizer,\n","    )\n","\n","    trainer.train()\n","\n","    metrics = compute_metrics(trainer.predict(tokenized_datasets[\"validation\"]))\n","\n","    return trainer.evaluate()['eval_loss'], metrics[\"f1\"]"]},{"cell_type":"markdown","id":"FvvfQ187ebEc","metadata":{"id":"FvvfQ187ebEc"},"source":["## **2.12 Train (or Tune)!**\n","Tuning:\n","-  set `enable_fine_tuning` to `True` if you want to search for new hyperparameters, default `False`\n","\n","Training:\n","- set `enable_fine_tuning` to `False`\n","- after training, save runs with `wandb`\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"GzlJegnseY80","metadata":{"id":"GzlJegnseY80"},"outputs":[],"source":["enable_fine_tuning = False\n","\n","if enable_fine_tuning:\n","  study = optuna.create_study(directions=['minimize', 'maximize'])\n","  study.optimize(objective, n_trials=10)\n","else:\n","  # start training\n","  trainer.train()\n","  wandb.finish()"]},{"cell_type":"markdown","id":"YqXuMiZkf6L1","metadata":{"id":"YqXuMiZkf6L1"},"source":["## **2.13 Save Model**\n","Save the model to `path` defined in 2.1 if you like\n"]},{"cell_type":"code","execution_count":null,"id":"lteiPNIE2XzE","metadata":{"id":"lteiPNIE2XzE"},"outputs":[],"source":["# only save model if results are better than logged results in wandb\n","is_saving = int(input(\"Do you want to save the model? \\n\" +\n","    f\"[0] no \\n\" +\n","    f\"[1] yes \\n\"))\n","\n","print(f\"Saving: yes\") if is_saving else print(f\"Saving: no\")\n","\n","if is_saving:\n","  trainer.save_model(f\"{path}/{model_name}_{setting}\")"]},{"cell_type":"markdown","id":"9mdEFXFYqAf3","metadata":{"id":"9mdEFXFYqAf3"},"source":["\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","id":"ZHaDwJZpqGzI","metadata":{"id":"ZHaDwJZpqGzI"},"source":["# **3. Predicting**"]},{"cell_type":"markdown","id":"H6aptdDwqZBP","metadata":{"id":"H6aptdDwqZBP"},"source":["## **3.1 Setting *path*-variable to load fine-tuned model**\n","- If saved locally, enter local path to load the model\n","- If Google Colab is used (and saved in Drive), please mount your Google Drive and enter the required path."]},{"cell_type":"code","execution_count":null,"id":"N0FNZHEtqWeE","metadata":{"id":"N0FNZHEtqWeE"},"outputs":[],"source":["from google.colab import drive\n","import google.colab\n","\n","model_path = \"./\"\n","\n","if 'google.colab' in str(get_ipython()):\n","  drive.mount('/content/drive')\n","\n","  user_input = str(input(\"Enter path to load the model: \"))# set path to directory for saving models\n","  model_path = user_input if user_input else model_path\n","  print(f\"Path: {model_path}\")\n","else:\n","  user_input = str(input(\"Enter path to load the model: \")) # set path to directory for saving models\n","  model_path = user_input if user_input else model_path\n","  print(f\"Path: {model_path}\")"]},{"cell_type":"markdown","id":"o9tlT-ISlhs4","metadata":{"id":"o9tlT-ISlhs4"},"source":["## **3.2 Mapping - Statement to CTR**\n"]},{"cell_type":"code","execution_count":null,"id":"b0Riea9Olbnf","metadata":{"id":"b0Riea9Olbnf"},"outputs":[],"source":["# maps all statements to their CTR\n","statement_to_id_test = {}\n","\n","count = 0\n","for instance in annotations[\"test\"]:\n","  statement_to_id_test[(count, instance[\"statement\"])] = instance[\"id\"]\n","  count += 1"]},{"cell_type":"markdown","id":"HUBymi_9x1yx","metadata":{"id":"HUBymi_9x1yx"},"source":["## **3.3 Loading saved Model and Tokenizer**\n","- saved model is loaded via `AutoModelForSequenceClassification`\n","- as tokenizer we use `AutoTokenizer` for the saved model\n","- `tokenize_function` is defined for mapping\n"]},{"cell_type":"code","execution_count":null,"id":"bHn3Aydkx1y4","metadata":{"id":"bHn3Aydkx1y4"},"outputs":[],"source":["# build ID to CTR mapping and transform data in data structure used by Tokenizer and Model\n","id_to_clinical_trial_record = id_to_CTR(raw_texts)\n","data = transform_data(annotations, id_to_clinical_trial_record, label2id, \"statement_only\")\n","\n","# Load the model configuration\n","config = AutoConfig.from_pretrained(model_path, num_labels=2, label2id=label2id, id2label=id2label, ignore_mismatched_sizes=True)\n","\n","# Load the model\n","model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","train_args = torch.load(f\"{model_path}training_args.bin\")\n","\n","def tokenize_function(examples):\n","    return tokenizer(\n","        examples[\"text\"],\n","        padding=\"longest\",\n","        truncation=\"only_first\",\n","        max_length=512)\n","\n","tokenized_datasets = data.map(tokenize_function, batched=True)"]},{"cell_type":"markdown","id":"yDa6QzGYzjuo","metadata":{"id":"yDa6QzGYzjuo"},"source":["## **3.4 Predict Labels for Test Set**\n","\n"]},{"cell_type":"code","execution_count":null,"id":"Lo5K9HiZly2E","metadata":{"id":"Lo5K9HiZly2E"},"outputs":[],"source":["# Put the model in evaluation mode\n","model.eval()\n","\n","trainer = Trainer(\n","    model=model,\n",")\n","\n","results = trainer.predict(tokenized_datasets[\"test\"])\n","predicted_labels = results.predictions.argmax(-1)"]},{"cell_type":"markdown","id":"Jt_lVTow3_GQ","metadata":{"id":"Jt_lVTow3_GQ"},"source":["## **3.5 Inspect Predictions**\n","- map labels to CTR-IDs of the statements\n"]},{"cell_type":"code","execution_count":null,"id":"BiJdiCE_1kme","metadata":{"collapsed":true,"id":"BiJdiCE_1kme"},"outputs":[],"source":["predicted_results = {}\n","\n","count = 0  # counter used to differentiate identical CTRs (expect the ID)\n","for sen, label in zip(tokenized_datasets[\"test\"][\"text\"], predicted_labels):\n","  mapped_label = id2label[label]\n","  id = statement_to_id_test[(count, sen)]\n","  count += 1\n","  print(mapped_label, \"\\t\", id)\n","\n","  predicted_results[id] = mapped_label"]},{"cell_type":"markdown","id":"8Rp30l7m24jI","metadata":{"id":"8Rp30l7m24jI"},"source":["## **3.6 Save Predictions**\n","You can save the dictionary `predicted_results` in a `json`-file if you like:"]},{"cell_type":"code","execution_count":null,"id":"UxFD_8xy3DxY","metadata":{"id":"UxFD_8xy3DxY"},"outputs":[],"source":["path_save = str(input(\"Enter path to save the predictions: \"))\n","\n","with open(path_save + \"predictions.json\", 'w') as json_file:\n","  json.dump(predicted_results, json_file)\n","\n","# Print the path to the saved file\n","print(f\"Results saved to: {path_save}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":5}
